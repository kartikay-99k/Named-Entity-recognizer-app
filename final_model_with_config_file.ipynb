{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c815c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    3.3.1                         \n",
      "Location         D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\n",
      "Platform         Windows-10-10.0.19043-SP0     \n",
      "Python version   3.9.12                        \n",
      "Pipelines        en_core_web_lg (3.3.0), en_core_web_md (3.3.0), en_core_web_sm (3.3.0), en_core_web_trf (3.3.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32aa5d97",
   "metadata": {
    "id": "32aa5d97"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "db = DocBin() # create a DocBin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e7864b",
   "metadata": {
    "id": "09e7864b"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('new_annotations.json')\n",
    "TRAIN_DATA = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0bcdd6",
   "metadata": {
    "id": "5d0bcdd6"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "\n",
    "# def trim_entity_spans(data: list) -> list:\n",
    "#     \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "#     Args:\n",
    "#         data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "#     Returns:\n",
    "#         list: The cleaned data.\n",
    "#     \"\"\"\n",
    "#     invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "#     cleaned_data = []\n",
    "#     for text, annotations in data:\n",
    "#         entities = annotations['entities']\n",
    "#         valid_entities = []\n",
    "#         for start, end, label in entities:\n",
    "#             valid_start = start\n",
    "#             valid_end = end\n",
    "#             while valid_start < len(text) and invalid_span_tokens.match(\n",
    "#                     text[valid_start]):\n",
    "#                 valid_start += 1\n",
    "#             while valid_end > 1 and invalid_span_tokens.match(\n",
    "#                     text[valid_end - 1]):\n",
    "#                 valid_end -= 1\n",
    "#             valid_entities.append([valid_start, valid_end, label])\n",
    "#         cleaned_data.append([text, {'entities': valid_entities}])\n",
    "\n",
    "#     return cleaned_data\n",
    "\n",
    "\n",
    "# final_data = trim_entity_spans(TRAIN_DATA['annotations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7e0235",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b7e0235",
    "outputId": "a97432bc-cad7-4b35-f432-8705d4815470"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 300.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for text, annot in tqdm(TRAIN_DATA['annotations']): \n",
    "    doc = nlp.make_doc(text) \n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "#         print(span ,\"->>>> \", label)\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents \n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./training_data.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5eca2d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5eca2d3",
    "outputId": "f61e6fc3-58c3-4700-bf70-8ffcf8222857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Generated config template specific for your use case\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-09 15:12:39,486] [INFO] Set up nlp object from config\n",
      "[2022-08-09 15:12:39,497] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-08-09 15:12:39,497] [INFO] Created vocabulary\n",
      "[2022-08-09 15:12:39,507] [INFO] Finished initializing nlp object\n",
      "[2022-08-09 15:12:40,836] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\typer\\main.py\", line 500, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\cli\\train.py\", line 45, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\cli\\train.py\", line 75, in train\n",
      "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\loop.py\", line 122, in train\n",
      "    raise e\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\loop.py\", line 105, in train\n",
      "    for batch, info, is_best_checkpoint in training_step_iterator:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\loop.py\", line 226, in train_while_improving\n",
      "    score, other_scores = evaluate()\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\loop.py\", line 281, in evaluate\n",
      "    scores = nlp.evaluate(dev_corpus(nlp))\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\language.py\", line 1400, in evaluate\n",
      "    examples = list(examples)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 142, in __call__\n",
      "    for real_eg in examples:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 164, in make_examples\n",
      "    for reference in reference_docs:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 197, in read_docbin\n",
      "    doc_bin = DocBin().from_disk(loc)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\tokens\\_serialize.py\", line 273, in from_disk\n",
      "    with path.open(\"rb\") as file_:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\pathlib.py\", line 1252, in open\n",
      "    return io.open(self, mode, buffering, encoding, errors, newline,\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\pathlib.py\", line 1120, in _opener\n",
      "    return self._accessor.open(self, flags, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'training_data.spacy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: .\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     85.68    0.93    0.60    2.09    0.01\n",
      "  2     200       2780.96   4053.31   44.32   47.60   41.46    0.44\n",
      "  4     400       1282.74   1336.03   89.36   90.97   87.80    0.89\n",
      "  6     600      10564.66    589.23   96.50   96.84   96.17    0.97\n",
      "  9     800        150.41    168.02   97.92   97.58   98.26    0.98\n",
      " 11    1000       1439.78    245.55   98.78   98.95   98.61    0.99\n",
      " 13    1200        179.28    104.40   99.13   98.96   99.30    0.99\n",
      " 16    1400        559.04    141.21   98.95   98.95   98.95    0.99\n",
      " 18    1600        300.78    131.26   97.89   98.59   97.21    0.98\n",
      " 21    1800        414.76    127.30   99.13   98.62   99.65    0.99\n",
      " 23    2000        167.95     72.87   99.48   99.65   99.30    0.99\n",
      " 26    2200        184.07     65.82   99.48   99.31   99.65    0.99\n",
      " 30    2400        332.79     67.66   99.30   99.65   98.95    0.99\n",
      " 34    2600        276.86     66.08   99.65   99.65   99.65    1.00\n",
      " 40    2800        380.57     97.25   99.65   99.65   99.65    1.00\n",
      " 47    3000        383.75     70.74   99.65   99.65   99.65    1.00\n",
      " 56    3200       3317.50     97.82   99.65   99.65   99.65    1.00\n",
      " 66    3400        126.42     48.00   99.65   99.65   99.65    1.00\n",
      "[!] Aborting and saving the final best model. Encountered exception:\n",
      "FileNotFoundError(2, 'No such file or directory')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba71dce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cba71dce",
    "outputId": "85de3b98-f3f7-4212-ab5c-9fb8db970a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: .\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-09 15:26:17,983] [INFO] Set up nlp object from config\n",
      "[2022-08-09 15:26:18,011] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-08-09 15:26:18,024] [INFO] Created vocabulary\n",
      "[2022-08-09 15:26:18,026] [INFO] Finished initializing nlp object\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\click\\core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\typer\\main.py\", line 500, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\cli\\train.py\", line 45, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\cli\\train.py\", line 72, in train\n",
      "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\initialize.py\", line 84, in init_nlp\n",
      "    nlp.initialize(lambda: train_corpus(nlp), sgd=optimizer)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\language.py\", line 1317, in initialize\n",
      "    proc.initialize(get_examples, nlp=self, **p_settings)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\pipeline\\tok2vec.py\", line 215, in initialize\n",
      "    validate_get_examples(get_examples, \"Tok2Vec.initialize\")\n",
      "  File \"spacy\\training\\example.pyx\", line 65, in spacy.training.example.validate_get_examples\n",
      "  File \"spacy\\training\\example.pyx\", line 44, in spacy.training.example.validate_examples\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 142, in __call__\n",
      "    for real_eg in examples:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 164, in make_examples\n",
      "    for reference in reference_docs:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 197, in read_docbin\n",
      "    doc_bin = DocBin().from_disk(loc)\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\site-packages\\spacy\\tokens\\_serialize.py\", line 273, in from_disk\n",
      "    with path.open(\"rb\") as file_:\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\pathlib.py\", line 1252, in open\n",
      "    return io.open(self, mode, buffering, encoding, errors, newline,\n",
      "  File \"D:\\Anaconda\\envs\\tensorflow-env\\lib\\pathlib.py\", line 1120, in _opener\n",
      "    return self._accessor.open(self, flags, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'training_data.spacy'\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55119531",
   "metadata": {
    "id": "55119531"
   },
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"./model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3080e6ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3080e6ad",
    "outputId": "54a23b58-0b49-4c18-84f5-85422aec75cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBI  ->>>  COMPANY\n",
      "SVARWOUARASTIIA PALARODETT  ->>>  EMPLOYEE_NAME\n",
      "AKXPP8096J  ->>>  PAN\n",
      "s20ase33003  ->>>  ACC_NUMBER\n",
      "41,315.00  ->>>  SALARY\n"
     ]
    }
   ],
   "source": [
    "t1 = \"IBI/SBI Pension Pension Slip BI HRMS Department March 2019  one SVARWOUARASTIIA PALARODETT Aadhear Wo Resistered in ms Address PF Index No  6332220 24 SRIPURAM COLONY PAN No. AKXPP8096J   a    aaa aa HYDERABAD - 500036 A/C Number  s20ase33003 HYDERABAD Mobile No.  9642753509 Andhra Pradesh India Date of Birth 22-06-1958 wai 8  peReasezaoo. con  Life certificate is due for submission  Earnings Deductions Basic Pension 26,810.00  Arrears of Deductions 8,936.00 Dearness Relief Pension 14,505.00  Commutation Pension 8,936.00  Arrears of earnings 41,315.00\"\n",
    "\n",
    "t2 = \"Payslip Adidas   abc road , india   Pay Date : 2022/08/17 Employee ID : 00678 Pay Period : 2022/08/01 - 2022/08/31 EmployeeName   : James Bondo UAN > 100011272933 Bank Acc + 3294826604393 PAN : PYPLG607M1 Earnings Deductions Basic Pay 59999 Tax 800 Allowance 500 PF 1800 Overtime 300 Total Earnings 60799 Total Deductions 2600 Net Pay 58199 INR 58199   Indian Rupee Thousand Ninety   Employer Signature Employee Signature   system generated payslip\"\n",
    "\n",
    "t3 = \"Cognizant   Cognizant Technology Solutions India Private Ltd   Payslip month 2019   Financial Period 2019 - 2020   Private & Confidential   Associate Information   Mr. Abhishek Dubey   Associate d 580636 Location COG Deccan Campus CDC SEZ .   Designation Sr . Associate - Projects PAN AQuooxxxxd   Gender Male Bank / C XAKXAAAS 72   Date Joining 07 - Jul-2016 ESI Number -   PF / C TN / MAS/31309/376281 Status Salary Credited   UAN 100751077315 Available Calendar Days 31   SA Policy - Paid Days 31   SA LIC ID - Loss Pay Days 0   Earnings Deductions   Basic 35,700 ProfessionTax 200   House Rent Allowance 16,000   Provident Fund 4,284   Conveyance Allowance 1,600 / TDS 19,682   Medical Allowance tv   Special Allowance 41,383   Project Specific Payout 62,444   Skill Premium Allowance 7,500   Total Earnings 164,627B Total Deduction 24,166 Net Salary = - B 140,461   computer generated payslip , valid authorized .   Registered Office : Cognizant Technology Solutions India Private Limited   5/535 , old Mahabalipuram Road , Chennai - 600 097 .\"\n",
    "\n",
    "t4 = \"OH   Wholetuber Manish Ltd   Payroll Slip   Employee Code 123123 Employee Manish Bhatnagar   Days Worked 30 JUAN Number 80010221931   State Haryana Department Youtube   Designation Creator PF Account Number 278532785432784   Date Joining 24/6/2018 Bank Account Number 3247325842   Salary Month Nov21   Earnings Deductions   Particulars Particulars Basic Salary 30,000 Provident Fund 3,600   House Rent Allowance 15,000 Deduction 1,200   ISpecial Allowance 10,000   Leave Travel Allowance 20,000   Washing Uniform Allowance 5,000   Books Periodicals Allowance :   Total Earnings 80,000 Total Deductions 4,800   Net Salary : Rs . 75200   Leave Details Leave Type Transfer Leave Purpose Leave   Closing Balance 6   29,04\"\n",
    "\n",
    "t5 = \"9/8/2018 Pay Slip   Alcon Laboratories India Pvt . Ltd.   Pay Slip Month JUNE 2018 EMP CODE : 40004264 LOCATION : TELANGANA EMPNAME : RATHNAKAR V SN PAN : ALWPV2882L DOJ : 01 - Dec-2011 PF : KN//19618/919 DESIGNATION : EQUIPMENT MANAGER - VR UAN : 100309243262 COST CENTRE : 6582780522 PAID DAYS 230 BANK : HDFC BANK LOP DAYS 20 ACCOUNT NUMBER : 01261050095226 NJ ARREAR DAYS 20   Uh NOVARTIS   EARNINGS   DEDUCTIONS   BASIC PAY 51,577.00   PROVIDENT FUND . HRA 25,789.00   INCOME TAX SUPPLEMENTARY ALLOWANCE 11,791.00   PROFESSION TAX   GROSS EARNINGS 89,157.00   GROSS DEDUCTIONS   NET PAY = : 77,400.00 WORDS : Rupees Seventy Seven Thousand   system generated document require signature . assistance / clarifications contact : Email : hroperations.indianovartis.com . Fax : +91 40 67584001 . Toll - free : 1800 108 4000 .   BB Modo - manage online data , Learn\"\n",
    "\n",
    "\n",
    "\n",
    "doc = nlp_ner(t1)\n",
    "for ent in doc.ents:\n",
    "  print(ent.text,\" ->>> \" , ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a9b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Bondo  ->>>  EMPLOYEE_NAME\n",
      "100011272933  ->>>  UAN\n",
      "3294826604393  ->>>  ACC_NUMBER\n",
      "PYPLG607M1  ->>>  PAN\n",
      "1800  ->>>  PF_DEDUCTION\n",
      "58199  ->>>  SALARY\n",
      "Adidas  ->>>  COMPANY\n"
     ]
    }
   ],
   "source": [
    "jum1 = \"Earnings Deductions Basic Pension 26,810.00 SVARWOUARASTIIA PALARODETT Aadhear Wo Resistered in ms Address Arrears of earnings 41,315.00 PF Index No  6332220 24 SRIPURAM COLONY PAN No. AKXPP8096J   a    aaa aa HYDERABAD - 500036 A/C Number  s20ase33003 HYDERABAD Mobile No.  9642753509 Andhra Pradesh India Date of Birth 22-06-1958 wai 8  peReasezaoo. con  Life certificate is due for submission Arrears of Deductions 8,936.00 Dearness IBI/SBI Pension Pension Slip BI HRMS Department March 2019 one Relief Pension 14,505.00  Commutation Pension 8,936.00 \"\n",
    "\n",
    "jum2 = \"Employee ID : : James Bondo UAN > 100011272933 Bank Acc + 3294826604393 PAN : PYPLG607M1 Earnings Deductions Basic Pay 59999 Tax 800 Allowance 500 PF 1800 Overtime 300 Total Earnings 60799 Total Deductions 2600 Net Pay 58199 INR 58199 Payslip Adidas abc road , india   Pay Date : 2022/08/17 Indian Rupee Thousand Ninety   Employer Signature Employee Signature 00678 Pay Period : 2022/08/01 - 2022/08/31 EmployeeName system generated payslip\"\n",
    "\n",
    "\n",
    "doc = nlp_ner(jum2)\n",
    "for ent in doc.ents:\n",
    "  print(ent.text,\" ->>> \" , ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f82fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "new_model1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
